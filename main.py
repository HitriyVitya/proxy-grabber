
import requests
from bs4 import BeautifulSoup
import re
import base64
import json
import asyncio
import time
from urllib.parse import urlparse, unquote, parse_qs, quote
import yaml

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
CHANNELS = [
    "shadowsockskeys",
    "oneclickvpnkeys",
    "v2ray_outlineir",  # –ò–∑ —Ç–≤–æ–µ–≥–æ —Å–∫—Ä–∏–Ω–∞
    "v2ray_free_conf",  # –ò–∑ —Ç–≤–æ–µ–≥–æ —Å–∫—Ä–∏–Ω–∞         # –î–æ–±–∞–≤–∏–ª –æ—Ç —Å–µ–±—è (–∂–∏—Ä–Ω—ã–π)
    "iSeqaro",          # –¢–æ–∂–µ –∂–∏—Ä–Ω—ã–π
]

# –¢–µ–ø–µ—Ä—å —ç—Ç–æ –†–ï–ê–õ–¨–ù–û —Å—Ä–∞–±–æ—Ç–∞–µ—Ç (–±—É–¥–µ—Ç –ª–∏—Å—Ç–∞—Ç—å –Ω–∞–∑–∞–¥)
MSG_LIMIT = 300 

# –¢–∞–π–º–∞—É—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Ä—Ç–∞
TIMEOUT = 2
GEOIP_BATCH_SIZE = 100

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def safe_base64_decode(s):
    s = s.strip()
    padding = len(s) % 4
    if padding:
        s += '=' * (4 - padding)
    try:
        return base64.urlsafe_b64decode(s).decode('utf-8', errors='ignore')
    except:
        return None

def get_flag_emoji(country_code):
    if not country_code: return ""
    return "".join(chr(ord(c) + 127397) for c in country_code.upper())

def batch_get_countries(ips):
    if not ips: return {}
    unique_ips = list(set(ips))
    ip_map = {}
    # –õ–∏–º–∏—Ç –¥–ª—è ip-api –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ
    print(f"üåç –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞–Ω—ã –¥–ª—è {len(unique_ips)} IP...")
    for i in range(0, len(unique_ips), GEOIP_BATCH_SIZE):
        batch = unique_ips[i:i + GEOIP_BATCH_SIZE]
        try:
            resp = requests.post(
                "http://ip-api.com/batch", 
                json=[{"query": ip, "fields": "countryCode"} for ip in batch],
                timeout=10
            )
            data = resp.json()
            for idx, result in enumerate(data):
                if 'countryCode' in result:
                    flag = get_flag_emoji(result['countryCode'])
                    original_ip = batch[idx]
                    ip_map[original_ip] = flag
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞–±–∞–Ω–∏–ª–∏ API
            time.sleep(0.5)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ GeoIP API: {e}")
    return ip_map

async def check_port(ip, port):
    try:
        conn = asyncio.open_connection(ip, port)
        reader, writer = await asyncio.wait_for(conn, timeout=TIMEOUT)
        writer.close()
        await writer.wait_closed()
        return True
    except:
        return False

def extract_ip_port(link):
    try:
        if link.startswith("vmess://"):
            b64 = link[8:]
            decoded = safe_base64_decode(b64)
            if decoded:
                data = json.loads(decoded)
                return data.get('add'), int(data.get('port'))
            return None, None
        
        parsed = urlparse(link)
        if link.startswith("ss://") and "@" in link:
            part = link.split("@")[-1]
            ip_port = part.split("/")[0].split("?")[0].split("#")[0]
            if ":" in ip_port:
                ip = ip_port.split(":")[0].replace("[", "").replace("]", "")
                port = int(ip_port.split(":")[1])
                return ip, port
            return None, None

        if parsed.hostname and parsed.port:
            return parsed.hostname, parsed.port
        return None, None
    except:
        return None, None

# --- –ì–õ–£–ë–û–ö–ò–ô –ü–ê–†–°–ò–ù–ì (–° –õ–∏—Å—Ç–∞–ª–∫–æ–π) ---
def get_raw_links():
    links = set()
    pattern = re.compile(r'(?:vless|vmess|ss|trojan|hysteria|hysteria2|hy2|tuic)://[^ \n<]+')
    
    for channel in CHANNELS:
        print(f"üîç –ö–∞–Ω–∞–ª: {channel}")
        channel_links = 0
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        url = f"https://t.me/s/{channel}"
        
        while True:
            try:
                resp = requests.get(url, timeout=10)
                if resp.status_code != 200: break
                
                soup = BeautifulSoup(resp.text, 'html.parser')
                messages = soup.find_all('div', class_='tgme_widget_message_text')
                
                if not messages: break
                
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
                for msg in messages:
                    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å—Å—ã–ª–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞ <a> —Å href, –∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–∫—Å—Ç–æ–º
                    text = msg.get_text()
                    found = pattern.findall(text)
                    for link in found:
                        clean = link.strip().rstrip('.,<>"\')]}')
                        links.add(clean)
                        channel_links += 1
                        
                    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–º href –∞—Ç—Ç—Ä–∏–±—É—Ç—ã (–∏–Ω–æ–≥–¥–∞ —Å—Å—ã–ª–∫–∞ —Å–ø—Ä—è—Ç–∞–Ω–∞ –ø–æ–¥ —Å–ª–æ–≤–æ–º)
                    for a in msg.find_all('a', href=True):
                        href = a['href']
                        if pattern.match(href):
                            links.add(href)
                            channel_links += 1

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –Ω–∞ –∫–∞–Ω–∞–ª
                if channel_links >= MSG_LIMIT:
                    print(f"   -> –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç ({channel_links} —Å—Å—ã–ª–æ–∫). –°—Ç–æ–ø.")
                    break
                
                # –ü–ê–ì–ò–ù–ê–¶–ò–Ø: –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ "–ü—Ä–µ–¥—ã–¥—É—â–∏–µ –ø–æ—Å—Ç—ã"
                # –û–±—ã—á–Ω–æ —ç—Ç–æ <a class="tme_messages_more" href="/s/channel?before=123">
                more_tag = soup.find('a', class_='tme_messages_more')
                
                if more_tag and 'href' in more_tag.attrs:
                    next_url = "https://t.me" + more_tag['href']
                    # –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∞ —Ç–∞ –∂–µ —Å–∞–º–∞—è (–∑–∞—Ü–∏–∫–ª–∏–ª–∏—Å—å), –≤—ã—Ö–æ–¥–∏–º
                    if next_url == url: break
                    url = next_url
                    # print(f"   -> –õ–∏—Å—Ç–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –Ω–∞–∑–∞–¥... –ù–∞–π–¥–µ–Ω–æ –ø–æ–∫–∞: {channel_links}")
                else:
                    print(f"   -> –ö–æ–Ω–µ—Ü –∏—Å—Ç–æ—Ä–∏–∏ –∫–∞–Ω–∞–ª–∞.")
                    break
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {channel}: {e}")
                break
        
        print(f"   ‚úÖ –ò—Ç–æ–≥–æ —Å –∫–∞–Ω–∞–ª–∞ {channel}: {channel_links}")

    return list(links)

def add_flag_to_link_and_get_name(link, ip, flag):
    name = "Proxy"
    new_link = link
    try:
        if link.startswith("vmess://"):
            b64 = link[8:]
            decoded = safe_base64_decode(b64)
            if decoded:
                data = json.loads(decoded)
                curr = data.get('ps', 'vmess')
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–ª–∞–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ üá©üá™ üá©üá™ Server
                curr = re.sub(r'[^\w\s\d\-\(\)\[\]]', '', curr).strip()
                name = f"{flag} {curr}" if flag else curr
                data['ps'] = name
                new_link = "vmess://" + base64.b64encode(json.dumps(data).encode('utf-8')).decode('utf-8')
        else:
            if "#" in link:
                main, tag = link.split("#", 1)
                tag = unquote(tag)
                tag = re.sub(r'[^\w\s\d\-\(\)\[\]]', '', tag).strip()
                name = f"{flag} {tag}" if flag else tag
                new_link = f"{main}#{quote(name)}"
            else:
                name = f"{flag} Server" if flag else "Server"
                new_link = f"{link}#{quote(name)}"
    except: pass
    return new_link, name

def link_to_clash_proxy(link):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞–ª"""
    try:
        if link.startswith("vmess://"):
            data = json.loads(safe_base64_decode(link[8:]))
            return {
                'name': data.get('ps', 'vmess'),
                'type': 'vmess',
                'server': data.get('add'),
                'port': int(data.get('port')),
                'uuid': data.get('id'),
                'alterId': int(data.get('aid', 0)),
                'cipher': 'auto',
                'udp': True,
                'tls': True if data.get('tls') == 'tls' else False,
                'skip-cert-verify': True,
                'network': data.get('net', 'tcp'),
                'ws-opts': {'path': data.get('path', '/'), 'headers': {'Host': data.get('host', '')}} if data.get('net') == 'ws' else None
            }
        
        if link.startswith("vless://") or link.startswith("trojan://"):
            parsed = urlparse(link)
            qs = parse_qs(parsed.query)
            proxy = {
                'name': unquote(parsed.fragment) if parsed.fragment else 'vless',
                'type': 'vless' if link.startswith('vless') else 'trojan',
                'server': parsed.hostname,
                'port': parsed.port,
                'uuid': parsed.username,
                'udp': True,
                'skip-cert-verify': True,
                'tls': True if qs.get('security', [''])[0] in ['tls', 'reality'] else False,
                'network': qs.get('type', ['tcp'])[0]
            }
            if link.startswith('trojan'):
                proxy['password'] = parsed.username
                del proxy['uuid']
            
            if qs.get('security', [''])[0] == 'reality':
                proxy['servername'] = qs.get('sni', [''])[0]
                proxy['reality-opts'] = {'public-key': qs.get('pbk', [''])[0], 'short-id': qs.get('sid', [''])[0]}
                proxy['client-fingerprint'] = qs.get('fp', ['chrome'])[0]
            elif proxy['tls'] and 'sni' in qs:
                proxy['servername'] = qs['sni'][0]
                
            if proxy['network'] == 'ws':
                proxy['ws-opts'] = {'path': qs.get('path', ['/'])[0]}
                if 'host' in qs: proxy['ws-opts'].setdefault('headers', {})['Host'] = qs['host'][0]
            if proxy['network'] == 'grpc':
                proxy['grpc-opts'] = {'grpc-service-name': qs.get('serviceName', [''])[0]}
            return proxy

        if link.startswith("ss://"):
            if "@" in link:
                main = link.split("#")[0]
                name = unquote(link.split("#")[1]) if "#" in link else "SS"
                part1 = main.split("@")[0].replace("ss://", "")
                part2 = main.split("@")[1]
                try:
                    decoded = safe_base64_decode(part1)
                    cipher, password = decoded.split(":", 1) if ":" in decoded else part1.split(":", 1)
                except:
                    cipher, password = part1.split(":", 1) if ":" in part1 else ("aes-256-gcm", part1)
                
                ip = part2.split(":")[0]
                port = int(part2.split(":")[1].split("/")[0])
                return {
                    'name': name, 'type': 'ss', 'server': ip, 'port': port,
                    'cipher': cipher, 'password': password, 'udp': True
                }
        return None
    except: return None

async def process_all(links):
    print(f"üßê –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(links)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫. –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–∑–≤–æ–Ω...")
    tasks = []
    items = [] 
    for link in links:
        ip, port = extract_ip_port(link)
        if ip and port: items.append((link, ip, port))
    
    async def verify(item):
        link, ip, port = item
        if await check_port(ip, port): return (link, ip)
        return None

    # –ü–∏–Ω–≥—É–µ–º
    results = await asyncio.gather(*(verify(i) for i in items))
    alive = [r for r in results if r is not None]
    
    print(f"‚úÖ –ñ–∏–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤: {len(alive)}. –ü–æ–ª—É—á–∞–µ–º —Ñ–ª–∞–≥–∏...")
    
    ips = [x[1] for x in alive]
    ip_flags = batch_get_countries(ips)
    
    final_links_list = []
    clash_proxies = []
    
    for link, ip in alive:
        flag = ip_flags.get(ip, "")
        new_link, pretty_name = add_flag_to_link_and_get_name(link, ip, flag)
        final_links_list.append(new_link)
        
        clash_obj = link_to_clash_proxy(new_link)
        if clash_obj:
            clash_obj['name'] = pretty_name
            # –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∏–º–µ–Ω
            while any(p['name'] == clash_obj['name'] for p in clash_proxies):
                clash_obj['name'] += f"_{len(clash_proxies)}"
            clash_proxies.append(clash_obj)
            
    return final_links_list, clash_proxies

def main():
    raw = get_raw_links()
    if not raw: return

    final_links, clash_data = asyncio.run(process_all(raw))
    
    if not final_links:
        print("‚ùå –í—Å–µ –º–µ—Ä—Ç–≤—ã–µ")
        # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª—ã
        for f_name in ["list.txt", "sub.txt", "proxies.yaml"]:
            with open(f_name, "w", encoding="utf-8") as f: f.write("")
        return

    # 1. list.txt
    with open("list.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(final_links))
        
    # 2. sub.txt
    b64 = base64.b64encode("\n".join(final_links).encode()).decode()
    with open("sub.txt", "w", encoding="utf-8") as f:
        f.write(b64)
        
    # 3. proxies.yaml
    clash_provider = {'proxies': clash_data}
    with open("proxies.yaml", "w", encoding="utf-8") as f:
        yaml.dump(clash_provider, f, allow_unicode=True, sort_keys=False)
        
    print(f"üéâ –ì–æ—Ç–æ–≤–æ! –ñ–∏–≤—ã—Ö: {len(final_links)}. –§–∞–π–ª—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")

if __name__ == "__main__":
    main()
